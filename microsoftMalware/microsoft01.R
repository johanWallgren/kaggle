library(data.table)
library(tidyverse)
library(tictoc)
library(xgboost)
library(pROC)

train <- as_tibble(fread("train.csv"))
test <- as_tibble(fread('test.csv'))

# Convert chars and bools to factors
# Skiping MachineIdentifier in col 1 since each row is unique
convertData <- function(df){
  for(i in 2:dim(df)[2]){
    if(class(df[[i]]) == 'character'){
      df[[i]] <- as.factor(df[[i]])
      
    }else  if(length(unique(df[[i]])) == 2 & max(df[[i]]) == 1 & min(df[[i]]) == 0){
      df[[i]] <- as.factor(df[[i]])
    }
  }
  return(df)
}

# Making sure that the levels are the same in train and test
# Assuming that colnames are same for df1 and df2 and that they have same size
fixLevels <- function(df1, df2){
  for(i in 1:dim(df2)[2]){
    
    if(class(df1[[i]]) == 'factor'){
      
      allLevels <- unique(c(levels(df1[[i]]),  levels(df2[[i]])))
      levels(df1[[i]]) <- allLevels
      levels(df2[[i]]) <- allLevels
    }
  }
return(list(df1, df2))
}

train <- convertData(train)
test <- convertData(test)

trainAndTest <- fixLevels(train, test)
save(trainAndTest, file = "trainAndTest.RData")


#######################################################################
load("trainAndTest.RData")
#######################################################################

train <- trainAndTest[[1]]
test <- trainAndTest[[2]]

# train <- sample_n(train, 5e6, replace = FALSE)

# Saving and removing MachineIdentifier
uniqueIDtrain <- train[1]
train <- select(train, -MachineIdentifier)

uniqueIDtest <- test[1]
test <- select(test, -MachineIdentifier)

smp_size <- floor(0.75 * nrow(train))
train_ind <- sample(seq_len(nrow(train)), size = smp_size)

trainTrain <- train[train_ind, ]
trainTest <- train[-train_ind, ]

#######################################################################

tic()
xgb <- xgboost(data = data.matrix(trainTrain[-dim(trainTrain)[2]]), 
               label = data.matrix(trainTrain[dim(trainTrain)[2]])-1,
               booster = 'gbtree',
               eta = 0.1, # step size of each boosting step
               nround = 200,
               eval_metric = 'rmse',
               objective = 'binary:logistic',
               tree_method = 'exact',
               max_depth = 10,
               subsample = 0.8,
               colsample_bytree = 0.8,
               callbacks = list(cb.early.stop(stopping_rounds = 3, verbose = TRUE))
)
toc()

hasDetectionTest <- trainTest[dim(trainTest)[2]] %>% mutate(HasDetections = as.integer(HasDetections)) - 1
predictTrainTest <- as_tibble(predict(xgb, data.matrix(trainTest[-dim(trainTest)[2]])))

rocVal <- roc(hasDetectionTest$HasDetections, predictTrainTest$value)
print(auc(rocVal))

predictTest <- as_tibble(predict(xgb, data.matrix(test))) 


submission <- bind_cols(as_tibble(uniqueIDtest$MachineIdentifier), as_tibble(predictTest$value)) %>%
  rename(MachineIdentifier = value, HasDetections = value1)

write.csv(x = submission, file = 'submission.csv', row.names = FALSE, quote = FALSE)





